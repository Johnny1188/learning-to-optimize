{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import lovely_tensors as lt # can be removed\n",
    "\n",
    "from l2o.others import w, detach_var, rsetattr, rgetattr, count_parameters, print_grads, \\\n",
    "    load_l2o_opter_ckpt, load_baseline_opter_ckpt, load_ckpt, dict_to_str, get_baseline_ckpt_dir\n",
    "from l2o.visualization import get_model_dot\n",
    "from l2o.training import do_fit, fit_normal, fit_optimizer, find_best_lr_normal\n",
    "from l2o.regularization import (\n",
    "    regularize_updates_translation_constraints,\n",
    "    regularize_updates_scale_constraints,\n",
    "    regularize_updates_rescale_constraints,\n",
    "    regularize_updates_constraints,\n",
    "    regularize_translation_conservation_law_breaking,\n",
    "    regularize_rescale_conservation_law_breaking,\n",
    ")\n",
    "from l2o.analysis import (\n",
    "    get_baseline_opter_param_updates,\n",
    "    collect_rescale_sym_deviations,\n",
    "    collect_translation_sym_deviations,\n",
    "    collect_scale_sym_deviations,\n",
    ")\n",
    "from l2o.data import MNIST, CIFAR10\n",
    "from l2o.optimizer import Optimizer\n",
    "from l2o.optimizee import (\n",
    "    MNISTSigmoid,\n",
    "    MNISTReLU,\n",
    "    MNISTNet,\n",
    "    MNISTNet2Layer,\n",
    "    MNISTNetBig,\n",
    "    MNISTRelu,\n",
    "    MNISTLeakyRelu,\n",
    "    MNISTSimoidBatchNorm,\n",
    "    MNISTReluBatchNorm,\n",
    "    MNISTConv,\n",
    "    MNISTReluBig,\n",
    "    MNISTReluBig2Layer,\n",
    "    MNISTMixtureOfActivations,\n",
    "    MNISTNetBig2Layer,\n",
    ")\n",
    "from l2o.meta_module import *\n",
    "from meta_test import meta_test, meta_test_baselines\n",
    "\n",
    "lt.monkey_patch() # can be removed\n",
    "sns.set(color_codes=True)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize L2O Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained L2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load previous checkpoint (and skip meta-training of a new l2O optimizer)\n",
    "opter, config, ckpt = load_ckpt(\n",
    "    dir_path=os.path.join(os.environ[\"CKPT_PATH\"], \"10-05-2023_13-26-17_MNISTReluBatchNorm_Optimizer\")\n",
    ")\n",
    "print(json.dumps(config, indent=4, default=str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-train a new L2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a new config\n",
    "config = { # global config\n",
    "    \"opter_cls\": Optimizer,\n",
    "    \"opter_config\": {\n",
    "        \"preproc\": True,\n",
    "        \"additional_inp_dim\": 0,\n",
    "        \"manual_init_output_params\": False,\n",
    "    },\n",
    "    \"eval_n_tests\": 5,\n",
    "    \"ckpt_base_dir\": datetime.now().strftime('%d-%m-%Y_%H-%M-%S'),\n",
    "    \"ckpt_baselines_dir\": \"baselines\",\n",
    "}\n",
    "\n",
    "config[\"meta_training\"] = { # training the optimizer\n",
    "    \"opter_cls\": config[\"opter_cls\"],\n",
    "    \"opter_config\": config[\"opter_config\"],\n",
    "    \"data_cls\": MNIST,\n",
    "    \"data_config\": {\n",
    "        \"batch_size\": 128,\n",
    "        # \"only_classes\": [0, 1],\n",
    "    },\n",
    "    \"optee_cls\": MNISTLeakyRelu,\n",
    "    \"optee_config\": {},\n",
    "    \"n_epochs\": 50,\n",
    "    \"n_optim_runs_per_epoch\": 20,\n",
    "    \"n_iters\": 200,\n",
    "    \"unroll\": 20,\n",
    "    \"n_tests\": 0,\n",
    "    \"optee_updates_lr\": 0.1,\n",
    "    \"opter_lr\": 0.001,\n",
    "    \"log_unroll_losses\": True,\n",
    "    \"opter_updates_reg_func\": None,\n",
    "    \"opter_updates_reg_func_config\": {},\n",
    "    \"reg_mul\": 0,\n",
    "    \"eval_iter_freq\": 10,\n",
    "    \"ckpt_iter_freq\": 5,\n",
    "    \"ckpt_dir\": None, # will be set later\n",
    "    \"load_ckpt\": None,\n",
    "    \"start_from_epoch\": 0,\n",
    "    \"verbose\": 2,\n",
    "}\n",
    "\n",
    "config[\"meta_testing\"] = { # testing the optimizer\n",
    "    \"data_cls\": config[\"meta_training\"][\"data_cls\"],\n",
    "    \"data_config\": config[\"meta_training\"][\"data_config\"],\n",
    "    \"optee_cls\": config[\"meta_training\"][\"optee_cls\"],\n",
    "    \"optee_config\": config[\"meta_training\"][\"optee_config\"],\n",
    "    \"unroll\": 1,\n",
    "    \"n_iters\": 1000,\n",
    "    \"optee_updates_lr\": config[\"meta_training\"][\"optee_updates_lr\"],\n",
    "    \"train_opter\": False,\n",
    "    \"opter_optim\": None,\n",
    "    \"ckpt_iter_freq\": 5,\n",
    "    \"ckpt_dir\": None, # will be set later\n",
    "}\n",
    "\n",
    "### additional config\n",
    "config[\"ckpt_base_dir\"] = f\"{config['ckpt_base_dir']}_{config['meta_training']['optee_cls'].__name__}_{config['opter_cls'].__name__}\"\n",
    "config[\"meta_training\"][\"ckpt_dir\"] = os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"], \"meta_training\")\n",
    "config[\"meta_testing\"][\"ckpt_dir\"] = os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"], \"meta_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create directories\n",
    "os.makedirs(os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"]), exist_ok=False)\n",
    "os.makedirs(config[\"meta_training\"][\"ckpt_dir\"], exist_ok=True)\n",
    "os.makedirs(config[\"meta_testing\"][\"ckpt_dir\"], exist_ok=True)\n",
    "\n",
    "### dump config\n",
    "with open(os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"], \"config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4, default=str)\n",
    "\n",
    "print(f\"Base directory: {config['ckpt_base_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta-train a new L2O optimizer model\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "best_training_loss, metrics, opter_state_dict = fit_optimizer(\n",
    "    **config[\"meta_training\"],\n",
    ")\n",
    "opter = w(\n",
    "    config[\"opter_cls\"](\n",
    "        **config[\"opter_config\"] if config[\"opter_config\"] is not None else {}\n",
    "    )\n",
    ")\n",
    "opter.load_state_dict(opter_state_dict)\n",
    "print(best_training_loss)\n",
    "\n",
    "### save the final model\n",
    "torch.save({\n",
    "    \"state_dict\": opter_state_dict,\n",
    "    \"config\": config,\n",
    "    \"loss\": best_training_loss,\n",
    "    \"metrics\": metrics,\n",
    "}, os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"], f\"l2o_optimizer.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optees_to_test = [\n",
    "    (MNISTRelu, {}),\n",
    "    (MNISTConv, {}),\n",
    "    (MNISTSigmoid, {\"layer_sizes\": [100, 100]}),\n",
    "    (MNISTReLU, {\"layer_sizes\": [100, 100]}),\n",
    "    (MNISTNet2Layer, {}),\n",
    "    (MNISTNetBig, {}),\n",
    "    (MNISTReluBatchNorm, {\"affine\": True, \"track_running_stats\": True}),\n",
    "    (MNISTNet, {}),\n",
    "    (MNISTLeakyRelu, {}),\n",
    "]\n",
    "baselines_to_test_against = [\n",
    "    (\"Adam\", optim.Adam, {\"lr\": find_best_lr_normal}),\n",
    "    (\"SGD\", optim.SGD, {\"lr\": find_best_lr_normal, \"momentum\": 0.9}),\n",
    "]\n",
    "use_existing_baselines = True # loads existing if exists, otherwise trains from scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-test L2O optimizer and baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = meta_test(\n",
    "    opter=opter,\n",
    "    optees=optees_to_test,\n",
    "    config=config,\n",
    "    save_ckpts_for_all_test_runs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baselines = meta_test_baselines(\n",
    "    baseline_opters=baselines_to_test_against,\n",
    "    optees=optees_to_test,\n",
    "    config=config,\n",
    "    use_existing_baselines=use_existing_baselines,\n",
    "    save_ckpts_for_all_test_runs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load all l2o metrics from disk\n",
    "l2o_metrics = {}\n",
    "\n",
    "for metrics_file in [f_name for f_name in os.listdir(os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"])) if f_name.startswith(\"metrics_\")]:\n",
    "    print(f\"Loading {metrics_file}\")\n",
    "    metrics_name = metrics_file[8:-4] # remove the \"metrics_\" prefix and \".npy\" suffix\n",
    "    l2o_metrics[metrics_name] = np.load(os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"], metrics_file), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load baseline metrics from disk\n",
    "baseline_metrics = dict()\n",
    "\n",
    "for optee_cls, optee_config in optees_to_test:\n",
    "    run_nickname = f\"{optee_cls.__name__}_{dict_to_str(optee_config)}_{config['meta_testing']['data_cls'].__name__}_{dict_to_str(config['meta_testing']['data_config'])}\"\n",
    "    baseline_metrics[run_nickname] = dict()\n",
    "    \n",
    "    ### load metrics for all considered baselines\n",
    "    for (opter_name, baseline_opter_cls, baseline_opter_config) in baselines_to_test_against:\n",
    "        baseline_opter_config_copy = deepcopy(baseline_opter_config)\n",
    "        \n",
    "        if \"lr\" in baseline_opter_config and callable(baseline_opter_config[\"lr\"]):\n",
    "            baseline_opter_config_copy[\"lr\"] = baseline_opter_config_copy[\"lr\"].__name__ # replace function with its name\n",
    "\n",
    "        baseline_dir_name = f\"{opter_name}_{dict_to_str(baseline_opter_config_copy)}\" \\\n",
    "            + f\"_{optee_cls.__name__}_{dict_to_str(optee_config)}\" \\\n",
    "            + f\"_{config['meta_testing']['data_cls'].__name__}_{dict_to_str(config['meta_testing']['data_config'])}\"\n",
    "        metrics_path = os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_baselines_dir\"], baseline_dir_name, \"metrics.npy\")\n",
    "        \n",
    "        ### load\n",
    "        print(f\"Loading {metrics_path}\")\n",
    "        baseline_metrics[run_nickname][opter_name] = np.load(metrics_path, allow_pickle=True).item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot meta-testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_max_iters = 500\n",
    "log_losses = False\n",
    "fig_save_dir = os.path.join(os.environ[\"CKPT_PATH\"], config[\"ckpt_base_dir\"])\n",
    "# fig_save_dir = None\n",
    "\n",
    "for optee_nickname, metrics in l2o_metrics.items():\n",
    "    if optee_nickname not in baseline_metrics:\n",
    "        continue\n",
    "    curr_baseline_metrics = baseline_metrics[optee_nickname]\n",
    "\n",
    "    ### plot comparison\n",
    "    fig = plt.figure(figsize=(26, 16))\n",
    "    fig.suptitle(f\"Meta-testing on {optee_nickname}\", fontsize=16, fontweight=\"bold\", y=0.92)\n",
    "    \n",
    "    for m_i, metric in enumerate([\"train_loss\", \"test_loss\", \"train_acc\", \"test_acc\"]):\n",
    "        ax = fig.add_subplot(2, 2, m_i + 1)\n",
    "        \n",
    "        ### baseline optimizers\n",
    "        for opter_name, opter_metrics in curr_baseline_metrics.items():\n",
    "            if \"test\" in metric:\n",
    "                x = np.arange(config[\"meta_training\"][\"eval_iter_freq\"], show_max_iters + 1, config[\"meta_training\"][\"eval_iter_freq\"])\n",
    "                y = np.mean(opter_metrics[metric][:,:show_max_iters // 10], axis=0)\n",
    "                y_min = np.min(opter_metrics[metric][:,:show_max_iters // 10], axis=0)\n",
    "                y_max = np.max(opter_metrics[metric][:,:show_max_iters // 10], axis=0)\n",
    "            else:\n",
    "                x = range(opter_metrics[metric][:,:show_max_iters].shape[1])\n",
    "                y = np.mean(opter_metrics[metric][:,:show_max_iters], axis=0)\n",
    "                y_min = np.min(opter_metrics[metric][:,:show_max_iters], axis=0)\n",
    "                y_max = np.max(opter_metrics[metric][:,:show_max_iters], axis=0)\n",
    "            sns.lineplot(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                label=opter_name,\n",
    "                linestyle=\"--\",\n",
    "                ax=ax,\n",
    "            )\n",
    "            ax.fill_between(\n",
    "                x=x,\n",
    "                y1=y_min,\n",
    "                y2=y_max,\n",
    "                alpha=0.1,\n",
    "            )\n",
    "\n",
    "            if log_losses:\n",
    "                # set y to log scale\n",
    "                if \"loss\" in metric:\n",
    "                    ax.set_yscale(\"log\")\n",
    "        \n",
    "        ### L2O optimizer\n",
    "        if \"test\" in metric:\n",
    "            x = np.arange(config[\"meta_training\"][\"eval_iter_freq\"], show_max_iters + 1, config[\"meta_training\"][\"eval_iter_freq\"])\n",
    "            y = np.mean(metrics[metric][:,:show_max_iters // config[\"meta_training\"][\"eval_iter_freq\"]], axis=0)\n",
    "            y_min = np.min(metrics[metric][:,:show_max_iters // config[\"meta_training\"][\"eval_iter_freq\"]], axis=0)\n",
    "            y_max = np.max(metrics[metric][:,:show_max_iters // config[\"meta_training\"][\"eval_iter_freq\"]], axis=0)\n",
    "        else:\n",
    "            x = range(metrics[metric][:,:show_max_iters].shape[1])\n",
    "            y = np.mean(metrics[metric][:,:show_max_iters], axis=0)\n",
    "            y_min = np.min(metrics[metric][:,:show_max_iters], axis=0)\n",
    "            y_max = np.max(metrics[metric][:,:show_max_iters], axis=0)\n",
    "        sns.lineplot(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            label=\"L2O\",\n",
    "            color=\"orange\",\n",
    "            linewidth=2,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            x=x,\n",
    "            y1=y_min,\n",
    "            y2=y_max,\n",
    "            alpha=0.2,\n",
    "            color=\"orange\",\n",
    "        )\n",
    "        \n",
    "        ### plot settings\n",
    "        ax.set_title(metric, fontsize=14, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Iteration\")\n",
    "        ax.set_ylabel(metric)\n",
    "        if \"acc\" in metric:\n",
    "            ax.set_ylim(0.6, 1.0)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ### save the figure\n",
    "    if fig_save_dir is not None:\n",
    "        prefix = \"log_losses\" if log_losses else \"losses\"\n",
    "        fig.savefig(os.path.join(fig_save_dir, f\"{prefix}_{optee_nickname}_{show_max_iters}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5692ede66a2eeda96ca4e496ad881a063b66ee8e9ec6003b28974c60439bc6fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
